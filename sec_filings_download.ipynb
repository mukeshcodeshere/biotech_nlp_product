{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import asyncio\n",
    "import logging\n",
    "import warnings\n",
    "import json\n",
    "from datetime import datetime\n",
    "from glob import glob\n",
    "from typing import List, Dict, Optional\n",
    "import datamule as dm\n",
    "import pandas as pd\n",
    "from selectolax.parser import HTMLParser\n",
    "from config import CONFIG  # Import the config dictionary\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Get today's date\n",
    "today = datetime.today()\n",
    "\n",
    "# Format the date in 'YYYY-MM-DD' format\n",
    "today_date = today.strftime('%Y-%m-%d')\n",
    "\n",
    "#Initialize parameters\n",
    "# tickers = ['AAPL', 'MSFT', 'GOOGL']\n",
    "# start = '2024-01-01'\n",
    "# end = '2024-06-01'#today_date\n",
    "# base_dir = 'sec_data'\n",
    "\n",
    "tickers = CONFIG['TICKERS']\n",
    "start = CONFIG['START_DATE']\n",
    "end = CONFIG['END_DATE']\n",
    "base_dir = CONFIG['BASE_DIR']\n",
    "\n",
    "class SECDownloader:\n",
    "    def __init__(self):\n",
    "        self.downloader = dm.Downloader()\n",
    "        logging.basicConfig(level=logging.INFO)\n",
    "        self.logger = logging.getLogger(__name__)\n",
    "        \n",
    "    def set_user_agent(self, user_agent: str) -> None:\n",
    "        \"\"\"Set SEC user agent information.\"\"\"\n",
    "        try:\n",
    "            self.downloader.set_headers(user_agent)\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Failed to set user agent: {str(e)}\")\n",
    "            raise\n",
    "            \n",
    "    async def download_filings(self, ticker: str, start_date: str, end_date: str, output_dir: str) -> None:\n",
    "        \"\"\"Download SEC filings with proper error handling.\"\"\"\n",
    "        try:\n",
    "            await self.downloader.download(\n",
    "                ticker=ticker,\n",
    "                form=['10-K', '10-Q', '8-K'],  # Specify forms explicitly\n",
    "                date=(start_date, end_date),\n",
    "                output_dir=output_dir,\n",
    "                return_urls=False  # Ensure we're downloading files\n",
    "            )\n",
    "        except ValueError as e:\n",
    "            self.logger.error(f\"Value error downloading filings for {ticker}: {str(e)}\")\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error downloading filings for {ticker}: {str(e)}\")\n",
    "\n",
    "    async def download_concepts(self, ticker: str, output_dir: str) -> None:\n",
    "        \"\"\"Download company concepts data with proper error handling.\"\"\"\n",
    "        try:\n",
    "            await self.downloader.download_company_concepts(\n",
    "                ticker=ticker,\n",
    "                output_dir=output_dir\n",
    "            )\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error downloading company concepts for {ticker}: {str(e)}\")\n",
    "\n",
    "    async def process_ticker(self, ticker: str, start: str, end: str, base_dir: str) -> None:\n",
    "        \"\"\"Process a single ticker's downloads.\"\"\"\n",
    "        try:\n",
    "            # Create directory structure\n",
    "            ticker_dir = os.path.join(base_dir, ticker)\n",
    "            filings_dir = os.path.join(ticker_dir, 'filings')\n",
    "            concepts_dir = os.path.join(ticker_dir, 'company_concepts')\n",
    "            \n",
    "            os.makedirs(filings_dir, exist_ok=True)\n",
    "            os.makedirs(concepts_dir, exist_ok=True)\n",
    "\n",
    "            # Download both filings and concepts concurrently\n",
    "            await asyncio.gather(\n",
    "                self.download_filings(ticker, start, end, filings_dir),\n",
    "                self.download_concepts(ticker, concepts_dir)\n",
    "            )\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Failed to process ticker {ticker}: {str(e)}\")\n",
    "\n",
    "    async def download_all_data(self, tickers: List[str], start: str, end: str, base_dir: str = 'sec_data') -> None:\n",
    "        \"\"\"Download all SEC data for given tickers.\"\"\"\n",
    "        tasks = []\n",
    "        for ticker in tickers:\n",
    "            task = self.process_ticker(ticker, start, end, base_dir)\n",
    "            tasks.append(task)\n",
    "        \n",
    "        await asyncio.gather(*tasks)\n",
    "\n",
    "# Initialize downloader\n",
    "sec_downloader = SECDownloader()\n",
    "\n",
    "try:\n",
    "    # Set user agent (required by SEC)\n",
    "    sec_downloader.set_user_agent(\"Your Name your@email.com\")\n",
    "    \n",
    "    # Create and run async download task\n",
    "    async def run_downloads():\n",
    "        await sec_downloader.download_all_data(tickers, start, end, base_dir)\n",
    "        \n",
    "    asyncio.run(run_downloads())\n",
    "    \n",
    "except KeyboardInterrupt:\n",
    "    sec_downloader.logger.warning(\"\\nDownload interrupted by user\")\n",
    "except Exception as e:\n",
    "    sec_downloader.logger.error(f\"Fatal error: {str(e)}\")\n",
    "finally:\n",
    "    sec_downloader.logger.info(\"Download process completed\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
